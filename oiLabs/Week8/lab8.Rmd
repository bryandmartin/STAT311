---
title: "Lab 8: Confidence Intervals and Hypothesis Testing for a Proportion"
output:
  html_document:
    css: ../lab.css
    highlight: pygments
    theme: cerulean
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
library(tidyverse)
download.file("http://www.openintro.org/stat/data/nc.RData", destfile = "nc.RData")
load("nc.RData")
```

<div id="boxedtext">
**Learning Objectives:**

+ Create confidence intervals and conduct hypothesis tests in R
+ Conduct a simulation experiment to explore the relationship between confidence intervals and hypothesis tests
+ Explore Type 1 and Type 2 errors through a simulation experiment. 
</div>

## The Data

In 2004, the state of North Carolina released a large data set containing information on births recorded in this state. This data set is useful to researchers studying the relation between habits and practices of expectant mothers and the birth of their children. We have access to a random sample of 1000 births. The sample can be loaded with the code below:

```{r, eval=TRUE, message=FALSE}
download.file("http://www.openintro.org/stat/data/nc.RData", destfile = "nc.RData")
load("nc.RData")
```

Two variables in this dataset that are of interest to policy makers are ``habit``, which records whether the mother was a smoker or a nonsmoker, and `lowbirthweight`, which records whether the baby was born with a `low` or a `not low` birthweight. Birth weight is an important predictor of infant morbidity and mortality, as well as long-term health
outcomes. There is a concern in public health that mothers who smoke are more likely to have underweight babies. We can see that this concern is supported by our sample. 

1. What proportion of babies in this sample had low birth weight? Report your answer to 3 decimal places. 

```{r, include=FALSE}
nc %>% select(lowbirthweight) %>% table() %>% prop.table()
```

2. What proportion of babies born to `habit=="smoker"` mothers had low birth weight? Report your answer to 3 decimal places.  

```{r, include=FALSE}
nc %>% filter(habit=="smoker") %>% select(lowbirthweight) %>% table() %>% prop.table()
```

It is known that in the state of North Carolina as a whole, 10\% of all babies have low birth weight. But we do not know what this proportion is for the subpopulation of mothers who smoke. For this lab, our population of interest is babies born to smoking mothers and our parameter of interest is $\pi$, the population proportion of babies born to smoking mothers who have low birth weight. We will treat the 126 babies born to smoking mothers as a random sample from this population. Our goal will be to **test the hypothesis** that $\pi$ is equal to 0.1. First we will estimate $\pi$ using a confidence interval. Afterwards, we will conduct a hypothesis test and explore what the hypothesis test actually means through simulation. 

3. For this investigation, the random sample that we are interested in only includes the babies born to smoking mothers.  Create a dataframe called ``nc_smoker`` that stores only the rows of the dataset where ``habit=="smoker"``. **Hint: use filter**.

```{r, eval=FALSE}
nc_smoker <- ### Fill in here
```

```{r, echo=FALSE, eval=TRUE}
nc_smoker <- nc %>% filter(habit=="smoker")
```

## Estimating with Confidence

In exercise 2, you computed $p$, the sample proportion of babies born to smoking mothers with low weight. We can use this sample proportion to create a 95\% confidence interval for the population proportion $\pi$. We could do this by hand as follows: be sure to fill in the appropriate value for $p$ and $n$ (sample size). Also be sure that you understand each step.

```{r, eval=FALSE}
p <- ### Fill in here.
n <- ### Fill in here
SE <- ### Enter plug-in standard error formula (uses phat and n)
multiplier <- ### Enter what you should multiply the SE by to get 95% confidence
lower <- p - multiplier*SE
upper <- p + multiplier*SE
lower 
upper
```


```{r, eval=TRUE, echo=FALSE, include=FALSE}
p <- nc_smoker %>% summarize(lbw = sum(lowbirthweight=="low")/n()) %>% as.numeric()
n <- 126
SE <- sqrt(p*(1-p)/n)
multiplier <- qnorm(0.975)
lower <- p - multiplier*SE
upper <- p + multiplier*SE
lower 
upper
```

4. Make a 95% confidence statement about the parameter in context.

```{r, echo=FALSE, eval=FALSE}
# We are 95% confident that the interval 8.2% to 20.4% contans the true proportion of babies born to smoking mothers who are underweight. In other words, values between 8.2% and 20.4% are plausible values for the proportion of babies born to smoking mothers who are underweight. Since this interval contains 0.1, it means that 0.1 (our null hypothesis) is a plausible value for the parameter; we are going to fail to reject the null.
```

<!-- 5. Modify your work above to create a 90% confidence interval for the same quantity. What changed?  -->

## Testing a Hypothesis

We start with the assumption that smoking does not increase the risk of a low birth weight baby, that is, $\pi = 0.1$. We can then calculate a p-value to see if our sample $p=0.14$ is abnormally large relative to this assumption

5. Set up a two-sided hypothesis test to test whether or not $\pi=0.1$ is plausible (write down the null and the alternative). 

<!-- We can use the `z.test` function in the `BSDA` package in R to calculate the p-value for this test. Note that you should install the BSDA package in your console before running this code.  -->

<!-- ```{r} -->
<!-- library(BSDA) -->
<!-- lowbirthweights <- nc_smoke$lowbirthweight == "low" -->
<!-- p0 <- 0.1 -->
<!-- sd0 <- sqrt(0.1*0.9) -->
<!-- lowbirthweights %>% z.test(alternative="two.sided", mu=p0, sigma.x=sd0, conf.level=0.95) -->
<!-- ``` -->

<!-- We should verify that we actually understand what this p-value means. -->

7. In a world where the null is true ($\pi=0.10$), what should the sampling distribution of $p$ look like? Fill in the blanks in the code below to plot the sampling distribution. 

```{r, eval=FALSE}
null_pi <- ## Fill in
null_se <- ## Fill in
ggplot(data = NULL, aes(x = seq(0,1,by=0.01))) +
        geom_blank() +
        stat_function(fun = dnorm, args = c(mean = null_pi, sd = null_se))
```

```{r, eval=TRUE, echo=FALSE, include=FALSE}
null_pi <- 0.1
null_se <- sqrt(0.1*0.9/128)
null_data <- data.frame(null_pi, null_se)
ggplot(data = null_data) +
        geom_blank() +
        stat_function(fun = dnorm, args = c(mean = null_pi, sd = null_se))
```

8. To see how our observed $p$ compares to the sampling distribution, we can add it to the plot above as a red vertical line. Make the same ggplot as the previous exercise, but now add `+geom_vline(xintercept=p, col = "red")` to the end of the command (make sure ``p`` is correctly defined).

```{r, echo=FALSE, include=FALSE}
ggplot(data = NULL, aes(x = seq(0,1,by=0.01))) +
        geom_blank() +
        stat_function(fun = dnorm, args = c(mean = null_pi, sd = sqrt((null_pi)*(1-null_pi)/126))) + geom_vline(xintercept=p, col = "red")
```

9. Compute a p-value for this test and explain how it relates to the plot from the previous exercise. Do you have convincing evidence to suggest that the proportion of smoking mothers who have low weight babies is not equal to 0.1? 

```{r, eval=FALSE, echo=FALSE, include=FALSE}
z <- (p - null_pi)/null_se
2*(1 - pnorm(z))
```

## Exploring with Simulation

Confidence intervals and p-values can be hard to wrap our heads around. In this section, we will perform some simulations to make sure we understand what confidence intervals and hypothesis tests are telling us. We will consider two different scenarios.

### Scenario 1: The Null Hypothesis is True

Let's create a fake population of 100,000 smoking mothers where 10\% of them have low birthweight babies. The code below makes a list of 100,000 0s and 1s, where 90\% are 0s (normal weight baby) and 10\% are 1s (underweight baby).

```{r, eval=TRUE}
popsize <- 100000
pop <- data.frame(lowbirthweight = c(rep(0, 0.9*popsize), rep(1, 0.1*popsize)))
```

Now let's take many different samples of 126 mothers from this population. In the following code, we take 10,000 samples. For each sample, we compute a 95\% confidence interval and a p-value for the hypothesis test based off of our sample. We will suppose that we are conducting hypothesis tests at the $\alpha=0.05$ significance level. We will use tools from the ``infer`` package to help us. You may need to run ``install.packages("infer")`` in your console prior to loading it.   

```{r, eval=TRUE, warning=FALSE}
library(infer)
set.seed(111)
pi0 <- 0.1
n <- 126
true_sd <- sqrt(pi0*(1-pi0)/n)
results <- pop %>%
        rep_sample_n(size = 126, reps = 10000) %>%
        summarise(p = mean(lowbirthweight), 
                  se = sqrt(p*(1-p)/126),
                  me = 1.96 * se,
                  lower = p - me,
                  upper = p + me,
                  correct_CI = (lower <= pi0 && upper >= pi0),
                  zscore = (p-pi0)/se,
                  pval = 2*(1-pnorm(abs(zscore))),
                  reject_null = pval <= 0.05)
```

1. The code takes our population data frame and creates 10000 samples of size 126. It then computes several summary statistics for each sample. Explan each piece of code in the ``summarise`` statement above in words: what does each column in ``results`` represent, and what formula or concept was used to compute it?<ul>
<li> p </li> 
<li> se</li> 
<li> me</li> 
<li> lower</li> 
<li> upper</li> 
<li> correct_CI</li> 
<li> zscore </li>
<li>  pval</li> 
<li> reject_null</li> 
</ul>

1. What was the smallest sample proportion you observed? Largest? 

11. In this case, since the true population proportion is 0.1, theory tells us that 95\% of our computed confidence intervals should cover 0.1. What percent of our intervals actually covered 0.1?

```{r, echo=FALSE, include=FALSE}
results %>% summarize(sum(correct_CI)/n())
```

Note that an interval covers 0.1 whenever $p$ is within 2 standard errors of $\pi$. We know that this should happen around 95\% of the time. 

12. In the simulation experiment above, we conducted the hypothesis test for 10,000 different samples. How many times did we make a type 1 error?

```{r, echo=FALSE, include=FALSE}
results %>% summarize(sum(reject_null))
```

13. How many times did we make a type 2 error? 

```{r, echo=FALSE, include=FALSE}
## 0: the null is true. 
```

<!-- 4. Make a histogram of the distribution of p-values. What do you notice? -->

<!-- ```{r, echo=FALSE, include=FALSE} -->
<!-- ggplot(data=results, aes(x=pval)) + geom_histogram(binwidth=0.05) -->
<!-- ``` -->

14. Recall our original hypothesis test with our original, real North Carolina sample. How many of our 10,000 samples in ``results`` had ``p`` with a zscore that was as large or larger (in magnitude) than the zscore
for the phat in the original sample? Relate this number to the original p-value. 

<!-- ### Scenario 2: The Null is False -->

<!-- Suppose that $p=0.13$, meaning that smoking mothers really are more likely to have underweight babies than the population as a whole. Let's create a hypothetical population where this is true.  -->

<!-- ```{r} -->
<!-- popsize <- 100000 -->
<!-- new_pop <- data.frame(lowbirthweight = c(rep(0, 0.87*popsize), rep(1, 0.13*popsize))) -->
<!-- ``` -->

<!-- Now let's repeat our previous simulation. Note that we as researchers don't **know** that the truth is 0.13, so this information will not be plugged in anywhere. We are still testing the null that p=0.1. -->

<!-- ```{r} -->
<!-- set.seed(311) -->
<!-- p0 <- 0.1 -->
<!-- n <- 126 -->
<!-- true_sd <- sqrt(p0*(1-p0)/n) -->
<!-- new_results <- new_pop %>% -->
<!--         rep_sample_n(size = 126, reps = 10000) %>% -->
<!--         summarise(phat = mean(lowbirthweight),  -->
<!--                   se = sqrt(phat*(1-phat)/126), -->
<!--                   me = 1.96 * se, -->
<!--                   lower = phat - me, -->
<!--                   upper = phat + me, -->
<!--                   CI_covers_truth = (lower < 0.13 && upper > 0.13), -->
<!--                   CI_covers_null = (lower < p0 && upper > p0), -->
<!--                   pval = 1-pnorm(phat, mean=p0, sd=true_sd), -->
<!--                   reject_null = pval < 0.05) -->
<!-- ``` -->

<!-- 1. What was the largest observed $\hat{p}$? The smallest?  -->

<!-- 1. **Quiz Question: ** How many times did you make a type 1 error? -->

<!-- ```{r, eval=FALSE, include=FALSE} -->
<!-- ### 0: the null is not true -->
<!-- ``` -->

<!-- 1. **Quiz Question: ** How many times did you make a type 2 error?  -->

<!-- ```{r, eval=FALSE, include=FALSE, echo=FALSE} -->
<!-- 10000-sum(new_results$reject_null) -->
<!-- ``` -->

<!-- 1. Would it have been reasonable to observe a sample such as our original sample (``nc`` dataset) in a population where $p=0.13$? To explain your answer, make a histogram of all of the ``phats`` in ``new_results`` and add a vertical line representing your original sample.  -->

<!-- <!-- 1. Make a histogram of the distribution of p values. What do you notice? -->

<!-- 1. Suppose you were to repeat the simulation one more time, but now suppose that the true $p$ is very large, at 0.2. How would the number or errors change? Explain.  -->

## Summary

In this lab, you computed a confidence interval based on a sample proportion and you also completed a test of a null hypothesis. You then explored how your confidence intervals and hypothesis tests would change from sample to sample in a scenario where the null hypothesis is true, but also in a scenario where the null hypothesis is false.

You should have seen that our sample of 126 smoking mothers **did not provide** sufficient evidence at the $\alpha=0.05$ level that the proportion of smoking mothers who have underweight babies ($\pi$) differs from 0.1. However, we certainly have not **proved** that $\pi=0.1$. Observing a sample such as ours is *not that rare* if $\pi=0.1$, but it is also *not that rare* under numerous other possible values of $\pi$. Hopefully this simulation convinced you of the importance of interpreting and understanding p-values.


## Acknowledgements

This lab is a modified version of an OpenIntro lab, modified by Anna Neufeld. 

<div id="license">
This is a product of OpenIntro that is released under a [Creative Commons 
Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0).
This lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.
</div>


